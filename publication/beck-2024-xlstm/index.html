<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=generator content="Wowchemy 5.0.0-beta.1 for Hugo">
<meta name=author content="Johannes Brandstetter">
<meta name=description content="How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs?">
<link rel=alternate hreflang=en-us href=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/>
<link rel=preconnect href=https://fonts.gstatic.com crossorigin>
<meta name=theme-color content="#1565c0">
<script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'">
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload="this.media='all'">
<script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script>
<script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap">
<link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'">
<link rel=stylesheet href=/css/wowchemy.b17ce4f35976ea0b0e8e0291231cd424.css>
<link rel=manifest href=/index.webmanifest>
<link rel=icon type=image/png href=/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_32x32_fill_lanczos_center_3.png>
<link rel=apple-touch-icon type=image/png href=/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_192x192_fill_lanczos_center_3.png>
<link rel=canonical href=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/>
<meta property="twitter:card" content="summary_large_image">
<meta property="og:site_name" content="Johannes Brandstetter">
<meta property="og:url" content="https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/">
<meta property="og:title" content="xLSTM -- Extended Long Short-Term Memory | Johannes Brandstetter">
<meta property="og:description" content="How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs?"><meta property="og:image" content="https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/featured.png">
<meta property="twitter:image" content="https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/featured.png"><meta property="og:locale" content="en-us">
<meta property="article:published_time" content="2024-05-07T12:55:17+02:00">
<meta property="article:modified_time" content="2024-05-07T12:55:17+02:00">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/"},"headline":"xLSTM -- Extended Long Short-Term Memory","image":["https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/featured.png"],"datePublished":"2024-05-07T12:55:17+02:00","dateModified":"2024-05-07T12:55:17+02:00","author":{"@type":"Person","name":"Maximilian Beck"},"publisher":{"@type":"Organization","name":"Johannes Brandstetter","logo":{"@type":"ImageObject","url":"https://brandstetter-johannes.github.io/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_192x192_fill_lanczos_center_3.png"}},"description":"How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs?"}</script>
<title>xLSTM -- Extended Long Short-Term Memory | Johannes Brandstetter</title>
</head>
<body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper>
<script src=/js/wowchemy-init.min.7de282f2047be3c570af3a58788341e7.js></script>
<aside class=search-modal id=search>
<div class=container>
<section class=search-header>
<div class="row no-gutters justify-content-between mb-3">
<div class=col-6>
<h1>Search</h1>
</div>
<div class="col-6 col-search-close">
<a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a>
</div>
</div>
<div id=search-box>
<input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...>
</div>
</section>
<section class=section-search-results>
<div id=search-hits>
</div>
</section>
</div>
</aside>
<div class=page-header>
<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main>
<div class=container>
<div class="d-none d-lg-inline-flex">
<a class=navbar-brand href=/>Johannes Brandstetter</a>
</div>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span>
</button>
<div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
<a class=navbar-brand href=/>Johannes Brandstetter</a>
</div>
<div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content>
<ul class="navbar-nav d-md-inline-flex">
<li class=nav-item>
<a class=nav-link href=/#about><span>Home</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#news><span>News</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#nxai><span>NXAI</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#research><span>Research</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#publications><span>Publications</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/experience/#experience><span>Experience</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/experience/#teaching><span>Teaching</span></a>
</li>
<li class=nav-item>
<a class=nav-link href=/#contact><span>Open Positions</span></a>
</li>
</ul>
</div>
<ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
<li class=nav-item>
<a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a>
</li>
<li class="nav-item dropdown theme-dropdown">
<a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences">
<i class="fas fa-moon" aria-hidden=true></i>
</a>
<div class=dropdown-menu>
<a href=# class="dropdown-item js-set-theme-light">
<span>Light</span>
</a>
<a href=# class="dropdown-item js-set-theme-dark">
<span>Dark</span>
</a>
<a href=# class="dropdown-item js-set-theme-auto">
<span>Automatic</span>
</a>
</div>
</li>
</ul>
</div>
</nav>
</div>
<div class=page-body>
<div class=pub>
<div class="article-container pt-3">
<h1>xLSTM -- Extended Long Short-Term Memory</h1>
<div class=article-metadata>
<div>
<span>
Maximilian Beck</span>, <span>
Korbinian Poeppel</span>, <span>
Markus Spanring</span>, <span>
Andreas Auer</span>, <span>
Oleksandra Prudnikova</span>, <span>
Michael Kopp</span>, <span>
Günter Klambauer</span>, <span>
Johannes Brandstetter</span>, <span>
Sepp Hochreiter</span>
</div>
<span class=article-date>
May 2024
</span>
<span class=middot-divider></span>
<span class=article-categories>
<i class="fas fa-folder mr-1"></i><a href=/category/large-language-models/>Large Language Models</a></span>
</div>
<div class="btn-links mb-3">
<a class="btn btn-outline-primary btn-page-header" href=https://arxiv.org/abs/2405.04517 target=_blank rel=noopener>
PDF
</a>
<a href=# class="btn btn-outline-primary btn-page-header js-cite-modal" data-filename=/publication/beck-2024-xlstm/cite.bib>
Cite
</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/NX-AI/xlstm target=_blank rel=noopener>
Code
</a>
</div>
</div>
<div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:675px;max-height:308px>
<div style=position:relative>
<img src=/publication/beck-2024-xlstm/featured.png alt class=featured-image>
<span class=article-header-caption>xLSTM family</span>
</div>
</div>
<div class=article-container>
<h3>Abstract</h3>
<p class=pub-abstract>In the 1990s, the constant error carousel and gating were introduced as the central ideas of the Long Short-Term Memory (LSTM). Since then, LSTMs have stood the test of time and contributed to numerous deep learning success stories, in particular they constituted the first Large Language Models (LLMs). However, the advent of the Transformer technology with parallelizable self-attention at its core marked the dawn of a new era, outpacing LSTMs at scale. We now raise a simple question: How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs? Firstly, we introduce exponential gating with appropriate normalization and stabilization techniques. Secondly, we modify the LSTM memory structure, obtaining: (i) sLSTM with a scalar memory, a scalar update, and new memory mixing, (ii) mLSTM that is fully parallelizable with a matrix memory and a covariance update rule. Integrating these LSTM extensions into residual block backbones yields xLSTM blocks that are then residually stacked into xLSTM architectures. Exponential gating and modified memory structures boost xLSTM capabilities to perform favorably when compared to state-of-the-art Transformers and State Space Models, both in performance and scaling.</p>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Type</div>
<div class="col-12 col-md-9">
<a href=/publication/#1>
Conference paper
</a>
</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=row>
<div class=col-md-1></div>
<div class=col-md-10>
<div class=row>
<div class="col-12 col-md-3 pub-row-heading">Publication</div>
<div class="col-12 col-md-9">Preprint</div>
</div>
</div>
<div class=col-md-1></div>
</div>
<div class="d-md-none space-below"></div>
<div class=space-below></div>
<div class=article-style></div>
<div class=article-tags>
<a class="badge badge-light" href=/tag/large-language-models/>Large Language Models</a>
<a class="badge badge-light" href=/tag/xlstm/>xLSTM</a>
<a class="badge badge-light" href=/tag/deep-learning/>Deep Learning</a>
</div>
<div class=share-box aria-hidden=true>
<ul class=share>
<li>
<a href="https://twitter.com/intent/tweet?url=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/&text=xLSTM%20--%20Extended%20Long%20Short-Term%20Memory" target=_blank rel=noopener class=share-btn-twitter>
<i class="fab fa-twitter"></i>
</a>
</li>
<li>
<a href="https://www.facebook.com/sharer.php?u=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/&t=xLSTM%20--%20Extended%20Long%20Short-Term%20Memory" target=_blank rel=noopener class=share-btn-facebook>
<i class="fab fa-facebook"></i>
</a>
</li>
<li>
<a href="mailto:?subject=xLSTM%20--%20Extended%20Long%20Short-Term%20Memory&body=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/" target=_blank rel=noopener class=share-btn-email>
<i class="fas fa-envelope"></i>
</a>
</li>
<li>
<a href="https://www.linkedin.com/shareArticle?url=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/&title=xLSTM%20--%20Extended%20Long%20Short-Term%20Memory" target=_blank rel=noopener class=share-btn-linkedin>
<i class="fab fa-linkedin-in"></i>
</a>
</li>
<li>
<a href="whatsapp://send?text=xLSTM%20--%20Extended%20Long%20Short-Term%20Memory%20https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/" target=_blank rel=noopener class=share-btn-whatsapp>
<i class="fab fa-whatsapp"></i>
</a>
</li>
<li>
<a href="https://service.weibo.com/share/share.php?url=https://brandstetter-johannes.github.io/publication/beck-2024-xlstm/&title=xLSTM%20--%20Extended%20Long%20Short-Term%20Memory" target=_blank rel=noopener class=share-btn-weibo>
<i class="fab fa-weibo"></i>
</a>
</li>
</ul>
</div>
<div class="article-widget content-widget-hr">
<h3>Related</h3>
<ul>
<li><a href=/publication/alkin-2024-vision-lstm/>Vision-LSTM -- xLSTM as Generic Vision Backbone</a></li>
<li><a href=/publication/ramsauer-2020-hopfield/>Hopfield Networks is All You Need</a></li>
<li><a href=/publication/widrich-2020-hopfield/>Modern hopfield networks and attention for immune repertoire classification</a></li>
<li><a href=/publication/alkin-2024-mimrefiner/>Mim-refiner -- A contrastive learning boost from intermediate pre-trained representations</a></li>
<li><a href=/publication/mayr-2021-bgnn/>Boundary Graph Neural Networks for 3D Simulations</a></li>
</ul>
</div>
</div>
</div>
</div>
<div class=page-footer>
<div class=container>
<footer class=site-footer>
<p class=powered-by>
</p>
<p class=powered-by>
Published with
<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> —
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>
open source</a> website builder that empowers creators.
</p>
</footer>
</div>
</div>
<div id=modal class="modal fade" role=dialog>
<div class=modal-dialog>
<div class=modal-content>
<div class=modal-header>
<h5 class=modal-title>Cite</h5>
<button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span>
</button>
</div>
<div class=modal-body>
<pre><code class="tex hljs"></code></pre>
</div>
<div class=modal-footer>
<a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank>
<i class="fas fa-copy"></i> Copy
</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank>
<i class="fas fa-download"></i> Download
</a>
<div id=modal-error></div>
</div>
</div>
</div>
</div>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script>
<script>const code_highlighting=!0</script>
<script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",event:"Events",slides:"Slides"}</script>
<script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script src=/js/wowchemy.min.d4185df71ecf716f1c4e7ef5f3d4e2b8.js></script>
</body>
</html>