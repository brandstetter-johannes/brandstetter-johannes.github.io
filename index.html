<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.0.0-beta.1 for Hugo"><meta name=author content="Johannes Brandstetter"><meta name=description content="Assistant Professor @ JKU Linz, VP Research @ NXAI"><link rel=alternate hreflang=en-us href=https://brandstetter-johannes.github.io/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.b17ce4f35976ea0b0e8e0291231cd424.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script><link rel=alternate href=/index.xml type=application/rss+xml title="Johannes Brandstetter"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://brandstetter-johannes.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Johannes Brandstetter"><meta property="og:url" content="https://brandstetter-johannes.github.io/"><meta property="og:title" content="Johannes Brandstetter"><meta property="og:description" content="Assistant Professor @ JKU Linz, VP Research @ NXAI"><meta property="og:image" content="https://brandstetter-johannes.github.io/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://brandstetter-johannes.github.io/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-06-06T12:55:17+02:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://brandstetter-johannes.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://brandstetter-johannes.github.io/"}</script><title>Johannes Brandstetter</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.cbbd96bcb05c8aeb233b6e67999f793a.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Johannes Brandstetter</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Johannes Brandstetter</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#news data-target=#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#nxai data-target=#nxai><span>NXAI</span></a></li><li class=nav-item><a class=nav-link href=/#research data-target=#research><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/experience/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/experience/#teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Open Positions</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" src=/authors/admin/avatar_hu1f007011a52cba17d97fb088d354cb34_1513563_270x270_fill_q98_lanczos_center.jpg alt="Johannes Brandstetter"><div class=portrait-title><h2>Johannes Brandstetter</h2><h3>Assistant Professor @ JKU Linz, VP Research @ NXAI</h3><h3><a href=https://www.jku.at/en/institute-for-machine-learning/ target=_blank rel=noopener><span>Johannes Kepler University, Linz, Institute for Machine Learning</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=https://github.com/brandstetter-johannes target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://twitter.com/jo_brandstetter target=_blank rel=noopener aria-label=twitter><i class="fab fa-twitter big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=KiRvOHcAAAAJ&amp;hl=en" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/johannes-brandstetter-55741b116/ target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li><li><a href=mailto:brandstetter@ml.jku.at aria-label=envelope><i class="far fa-envelope big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>About me</h1><div class=article-style><p>I am leading a group &ldquo;AI for data-driven simulations&rdquo; at the <a href=https://www.jku.at/en/institute-for-machine-learning/ target=_blank rel=noopener>Institute for Machine Learning</a> at the Johannes Kepler University (JKU) Linz. Additionally, I am a VP Research at <a href=https://www.nx-ai.com/ target=_blank rel=noopener>NXAI</a> - our new European AI hub in Linz (Austria).</p><p>I have obtained my PhD after working several years at the <a href=https://cms.cern/ target=_blank rel=noopener>CMS experiment at CERN</a>. During this time, I had the privilege of learning from brilliant minds from all around the world, and got the chance to co-author seminal papers in the realm of Higgs boson physics. In 2018, after completing my PhD, my career trajectory shifted towards machine learning, and I was fortunate to join the research group of Mr LSTM Sepp Hochreiter in Linz. Under Sepp&rsquo;s mentorship, I delved into the intricacies of machine learning and modern deep learning over a span of 2.5 years.</p><p>From 2021 to 2023, I had the pleasure of spending three remarkable years in Amsterdam.
Initially, I was part of the <a href=https://amlab.science.uva.nl/ target=_blank rel=noopener>Amsterdam Machine Learning Lab</a> lead by Max Welling, and subsequently joined Microsoft Research for 2 years. During this period, my passion for Geometric Deep Learning, particularly involving <a href=https://microsoft.github.io/cliffordlayers/ target=_blank rel=noopener>Geometric (Clifford) algebras</a>, and my interest in partial differential equations (PDEs), with a particular focus on <a href=https://microsoft.github.io/pdearena/ target=_blank rel=noopener>developing neural surrogates for (PDEs)</a>, became profound. Most importantly, I pivoted towards large-scale PDEs, <a href=https://microsoft.github.io/ClimaX/ target=_blank rel=noopener>including weather and climate modeling</a>, which culminated in <a href=https://arxiv.org/abs/2405.13063 target=_blank rel=noopener>Aurora</a>.</p><p>My years in Amsterdam have shaped <a href=https://brandstetter-johannes.github.io/research/data-driven-simulations/ target=_blank rel=noopener>my research vision</a>. I am firmly convinced that AI is on the cusp of disrupting simulations at industry-scale. Every day thousands and thousands of compute hours are spent on turbulence modeling, simulations of fluid or air flows, heat transfer in materials, traffic flows, and many more. Many of these processes follow similar underlying patterns, but yet need different and extremely specialized softward to simulate. Even worse, for different parameter settings the costly simulations need to be run at full length from scratch.</p><p>This is what I want to change! Therefore, I have started a new group at JKU Linz which has strong computer vision, numerical simulation, and engineering components. We want to advance data-driven simulations at industry-scale, and place the Austrian industry engine Linz as a center for doing that.</p></div><div class=row></div></div></div></div></section><section id=news class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>News</h1></div><div class="col-12 col-lg-8"><style type=text/css rel=stylesheet>li:not(:last-child){margin-bottom:7px}</style><div style=overflow-y:scroll;max-height:400px><p><strong>[Feb 2024]</strong> I have started as Head of Research (AI4Simulations) at <a href=https://www.nx-ai.com/ target=_blank rel=noopener>NXAI</a>.</p><p><strong>[Nov 2023]</strong> I am featured in the <a href=https://background.tagesspiegel.de/digitalisierung/ki-simulationen-fuer-die-industrie target=_blank rel=noopener>Tagesspiegel: ki-simulationen-fuer-die-industrie</a>.</p><p><strong>[Nov 2023]</strong> I am featured in the <a href=https://industriemagazin.at/news/ai-forscher-johannes-brandstetter-der-rueckkehrer/ target=_blank rel=noopener>Industriemagazin: ai-forscher-johannes-brandstetter-der-rueckkehrer/</a>.</p><p><strong>[Nov 2023]</strong> ReThink Compliance! I am participating in a public discussion <a href=https://businesscircle.at/compliance/konferenz/compliance-now/ target=_blank rel=noopener>ReThink Compliance!</a> at Stegersbach.</p><p><strong>[Nov 2023]</strong> invest.austria conference! I am participating in a public discussion <a href="https://www.invest-austria.com/de/invest-austria-conference/?gclid=Cj0KCQiAuqKqBhDxARIsAFZELmJ2_f4lQ1aM7rDWudlBjWY2_l06cvXroPXVW7_RAkcKeSeDryBRRe0aApLbEALw_wcB" target=_blank rel=noopener>The Rise of AI: Opportunities and Threats</a> at gorgeous Apothekertrakt Schönbrunn in Vienna.</p><p><strong>[Oct 2023]</strong> PoliTalk &ldquo;Wehrhafte Demokratie – Kampf gegen Fake News und Manipulation&rdquo;. I discussed with the head of state Thomas Stelzer and Ulrike Schiesser on the role of AI when it comes to spreading fake news.</p><p><strong>[Oct 2023]</strong> AI Venture Hub @ Ars Electronica Center Linz! I discussed with Robert Weber, host of the <a href=https://aipod.de/ target=_blank rel=noopener>Industrial AI Podcast</a>, about what it takes to make Linz a worldwide AI hub.</p><p><strong>[Oct 2023]</strong> SimTech2023! I presented our paper <a href=https://brandstetter-johannes.github.io/publication/nguyen-2023-climax/ target=_blank rel=noopener>ClimaX &ndash; A foundation model for weather and climate</a> at the International Conference on Data-Integrated Simulation Science (SimTech2023) in Stuttgart.</p><p><strong>[Oct 2023]</strong> I have started my own group &ldquo;AI for data-driven simulations” at the <a href=https://www.jku.at/en/institute-for-machine-learning/ target=_blank rel=noopener>Institute for Machine Learning</a> at the Johannes Kepler University (JKU) Linz.</p><p><strong>[Sep 2023]</strong> Three papers accepted at NeurIPS 2023! We will present <a href=https://brandstetter-johannes/publication/ruhe-2023-cgenns/ target=_blank rel=noopener>Clifford Group Equivariant Neural Networks</a> as oral, <a href=https://brandstetter-johannes.github.io/publication/lippe-2023-pderefiner/ target=_blank rel=noopener>PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers</a> as spotlight and <a href=https://brandstetter-johannes.github.io/publication/akhound-sadegh-2023-lps-pinn/ target=_blank rel=noopener>Lie Point Symmetries and Physics-Informed Networks</a> as poster in New Orleans.</p></div></div></div></div></section><section id=nxai class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>NXAI</h1></div><div class="col-12 col-lg-8"><style type=text/css rel=stylesheet>li:not(:last-child){margin-bottom:7px}</style><div style=overflow-y:scroll;max-height:400px><p><strong>Mission statement of NXAI</strong></p><p>With NXAI, we are building an European AI hub that comprises world-class research, close ties to local universities, and strong industrial know-how and support. Our mission is to create a large-scale entrepreneurial framework to transform latest scientific developments into industrial-ready applications.</p><p>At its core, NXAI is dedicated to independent research, which we believe is our greatest strength. However, we aspire to go further. We are building a pipeline that converts our research into high-impact industrial applications. Our goal is to become a nimble AI powerhouse at the forefront of the AI revolution in Europe.</p><p>Our research focus is on two key areas. The first is AI4Simulation, where we are building foundational models for industrial simulations. The second is Large Language Models (LLMs), highlighted by our flagship project xLSTM. In both domains, we have world-leading experts committed to unlocking the vast potential for creating downstream applications for engineering and industrial use cases</p><p>More information can be found at our webpage <a href=https://www.nx-ai.com/ target=_blank rel=noopener>https://www.nx-ai.com/</a>.</p></div></div></div></div></section><section id=research class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Research</h1></div><div class="col-12 col-lg-8"><div class=card-simple><div class=article-metadata><span class=article-date>Oct 1, 2023</span></div><a href=/research/data-driven-simulations/><div class=img-hover-zoom><img src=/research/data-driven-simulations/featured_hue401cb86d10535f004ebf0cc43f5e634_94256_77c7abc521347cc0595e7fca117ee9ef.jpg data-src=/research/data-driven-simulations/featured_hue401cb86d10535f004ebf0cc43f5e634_94256_808x455_fill_q98_lanczos_smart1.jpg class="article-banner lazyload" alt="Data-Driven Simulations"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/data-driven-simulations/>Data-Driven Simulations</a></div><a href=/research/data-driven-simulations/ class=summary-link><div class=article-style><p>I am firmly convinced that AI is on the cusp of disrupting simulations at industry-scale. Therefore, I have started a new group at JKU Linz which has strong computer vision, simulation, and engineering components. My vision is shaped by experience both from university and from industry.</p></div></a></div><div class=card-simple><div class=article-metadata><span class=article-date>Jan 1, 2021</span></div><a href=/research/geometric-deep-learning/><div class=img-hover-zoom><img src=/research/geometric-deep-learning/featured_hu7b08722431809de100db678e0bffd13c_206534_d4b701889b35ba8dd17722c20929a93e.png data-src=/research/geometric-deep-learning/featured_hu7b08722431809de100db678e0bffd13c_206534_808x455_fill_lanczos_smart1_3.png class="article-banner lazyload" alt="Geometric Deep Learning"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/geometric-deep-learning/>Geometric Deep Learning</a></div><a href=/research/geometric-deep-learning/ class=summary-link><div class=article-style><p>My passion for Geometric Deep Learning can be unmistakenly traced back to my physics background. I have contributed to the fields of graph neural networks, equivariant architectures, and neural PDE solvers. Furthermore, I have lead efforts to introduce Lie Point Symmetries, and, most recently, Clifford (Geometric) Algebras into the Deep Learning community.</p></div></a></div><div class=card-simple><div class=article-metadata><span class=article-date>Jul 1, 2018</span></div><a href=/research/deep-learning/><div class=img-hover-zoom><img src=/research/deep-learning/featured_huf25e885b1382cb4857aade30badbe625_95866_8dad8ff826763cc5cef3566170f17fd2.jpg data-src=/research/deep-learning/featured_huf25e885b1382cb4857aade30badbe625_95866_808x455_fill_q98_lanczos_smart1.jpg class="article-banner lazyload" alt="General Deep Learning"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/deep-learning/>General Deep Learning</a></div><a href=/research/deep-learning/ class=summary-link><div class=article-style><p>After switching from High Energy Physics to Deep Learning, I started working in Reinforcement Learning before pivoting towards Associative Memories and modern Transformer networks. Recent years have shown that scalable ideas, improving the datasets, and clever engineering are the ingredients for ever better Deep Learning models. This totally coincides with my experience, and &ndash; needless to say &ndash; I will continue working on general large-scale Deep Learning directions.</p></div></a></div><div class=card-simple><div class=article-metadata><span class=article-date>Jan 1, 2014</span></div><a href=/research/high-energy-physics/><div class=img-hover-zoom><img src=/research/high-energy-physics/featured_hud771b9de0130cb391febb22251a3c944_589960_7f657de0bb61435ccdd77358dfae50f1.jpg data-src=/research/high-energy-physics/featured_hud771b9de0130cb391febb22251a3c944_589960_808x455_fill_q98_lanczos_smart1.jpg class="article-banner lazyload" alt="High Energy Physics"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/high-energy-physics/>High Energy Physics</a></div><a href=/research/high-energy-physics/ class=summary-link><div class=article-style><p>I have spent five years (including my PhD) working in the CMS Collaboration at CERN. Most of my research was dedicated to Higgs boson physics.</p></div></a></div></div></div></div></section><section id=publications class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Recent (selected) Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/alkin-2024-vision-lstm/>Vision-LSTM -- xLSTM as Generic Vision Backbone</a></div><a href=/publication/alkin-2024-vision-lstm/ class=summary-link><div class=article-style>We introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to computer vision.</div></a><div class="stream-meta article-metadata"><div><span>Benedikt Alkin</span>, <span>Maximilian Beck</span>, <span>Korbinian Poeppel</span>, <span>Sepp Hochreiter</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2406.04303 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/alkin-2024-vision-lstm/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/nx-ai/vision-lstm target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://nx-ai.github.io/vision-lstm/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/alkin-2024-vision-lstm/><img src=/publication/alkin-2024-vision-lstm/featured_hudc4623eacaae69c19ae834e37cff285c_36506_e437b74b6f5d8a5f1fb330f4e22ff240.png data-src=/publication/alkin-2024-vision-lstm/featured_hudc4623eacaae69c19ae834e37cff285c_36506_150x0_resize_lanczos_3.png alt="Vision-LSTM -- xLSTM as Generic Vision Backbone" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/bodnar-2024-aurora/>Aurora -- A foundation Model of the Atmosphere</a></div><a href=/publication/bodnar-2024-aurora/ class=summary-link><div class=article-style>Aurora leverages the strengths of the foundation modelling approach to produce operational forecasts for a wide variety of atmospheric prediction problems, including those with limited training data, heterogeneous variables, and extreme events</div></a><div class="stream-meta article-metadata"><div><span>Cristian Bodnar</span>, <span>Wessel W. Bruinsma</span>, <span>Ana Lucic</span>, <span>Megan Stanley</span>, <span>Johannes Brandstetter</span>, <span>Patrick Garvan</span>, <span>Maik Riechert</span>, <span>Jonathan Weyn</span>, <span>Haiyu Dong</span>, <span>Anna Vaughan</span>, <span>Jayesh K. Gupta</span>, <span>Kit Tambiratnam</span>, <span>Alex Archibald</span>, <span>Elizabeth Heider</span>, <span>Max Welling</span>, <span>Rich E. Turner</span>, <span>Paris Perdikaris</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.13063 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/bodnar-2024-aurora/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/bodnar-2024-aurora/><img src=/publication/bodnar-2024-aurora/featured_hu2e05b0091c591a24c8fe12ec320bac9f_493434_021713b50ff83196d70af531b1cab84b.png data-src=/publication/bodnar-2024-aurora/featured_hu2e05b0091c591a24c8fe12ec320bac9f_493434_150x0_resize_lanczos_3.png alt="Aurora -- A foundation Model of the Atmosphere" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/beck-2024-xlstm/>xLSTM -- Extended Long Short-Term Memory</a></div><a href=/publication/beck-2024-xlstm/ class=summary-link><div class=article-style>How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs?</div></a><div class="stream-meta article-metadata"><div><span>Maximilian Beck</span>, <span>Korbinian Poeppel</span>, <span>Markus Spanring</span>, <span>Andreas Auer</span>, <span>Oleksandra Prudnikova</span>, <span>Michael Kopp</span>, <span>Günter Klambauer</span>, <span>Johannes Brandstetter</span>, <span>Sepp Hochreiter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.04517 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/beck-2024-xlstm/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/NX-AI/xlstm target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/beck-2024-xlstm/><img src=/publication/beck-2024-xlstm/featured_hu96a6b6c3934663291bddbc1f38c55003_45653_6cbb14190b190118df507f15f771a4b0.png data-src=/publication/beck-2024-xlstm/featured_hu96a6b6c3934663291bddbc1f38c55003_45653_150x0_resize_lanczos_3.png alt="xLSTM -- Extended Long Short-Term Memory" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/berzins-2024-ginns/>Geometry-Informed Neural Networks</a></div><a href=/publication/berzins-2024-ginns/ class=summary-link><div class=article-style>We introduce geometry-informed neural networks (GINNs) to train shape generative models without any data.</div></a><div class="stream-meta article-metadata"><div><span>Arturs Berzins</span>, <span>Andreas Radler</span>, <span>Sebastian Sanokowski</span>, <span>Sepp Hochreiter</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.14009 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/berzins-2024-ginns/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ml-jku/GINNs-Geometry-informed-Neural-Networks target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arturs-berzins.github.io/GINN/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/berzins-2024-ginns/><img src=/publication/berzins-2024-ginns/featured_hu37d8aae38d48dfc801ecb4736e7af687_692903_eabd3f947e9b8ea73fd66b3777c59c49.png data-src=/publication/berzins-2024-ginns/featured_hu37d8aae38d48dfc801ecb4736e7af687_692903_150x0_resize_lanczos_3.png alt="Geometry-Informed Neural Networks" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/alkin-2024-upt/>Universal Physics Transformers -- A Framework For Efficiently Scaling Neural Operators</a></div><a href=/publication/alkin-2024-upt/ class=summary-link><div class=article-style>We introduce Universal Physics Transformers (UPTs), an efficient and unified learning paradigm for a wide range of spatio-temporal problems. UPTs operate without grid- or particle-based latent structures, enabling flexibility and scalability across meshes and particles.</div></a><div class="stream-meta article-metadata"><div><span>Benedikt Alkin</span>, <span>Andreas Fürst</span>, <span>Simon Schmid</span>, <span>Lukas Gruber</span>, <span>Markus Holzleitner</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.12365 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/alkin-2024-upt/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ml-jku/UPT target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ml-jku.github.io/UPT/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/alkin-2024-upt/><img src=/publication/alkin-2024-upt/featured_hu8b80630a582cbf42c3458ce96d5a4590_157838_1789609c5e2488d2efbb1e27275ceddb.png data-src=/publication/alkin-2024-upt/featured_hu8b80630a582cbf42c3458ce96d5a4590_157838_150x0_resize_lanczos_3.png alt="Universal Physics Transformers -- A Framework For Efficiently Scaling Neural Operators" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/alkin-2024-mimrefiner/>Mim-refiner -- A contrastive learning boost from intermediate pre-trained representations</a></div><a href=/publication/alkin-2024-mimrefiner/ class=summary-link><div class=article-style>We introduce MIM (Masked Image Modeling)-Refiner, a contrastive learning boost for pre-trained MIM models.</div></a><div class="stream-meta article-metadata"><div><span>Benedikt Alkin</span>, <span>Lukas Miklautz</span>, <span>Sepp Hochreiter</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.10093 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/alkin-2024-mimrefiner/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ml-jku/MIM-Refiner target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ml-jku.github.io/MIM-Refiner/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/alkin-2024-mimrefiner/><img src=/publication/alkin-2024-mimrefiner/featured_hu5a9807048c46ae96d8b399109037ff64_47175_9363d30b4d206a43165d9a31b6d92bd9.png data-src=/publication/alkin-2024-mimrefiner/featured_hu5a9807048c46ae96d8b399109037ff64_47175_150x0_resize_lanczos_3.png alt="Mim-refiner -- A contrastive learning boost from intermediate pre-trained representations" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/toshev-2024-neuralsph/>We identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of GNN-based simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components.</a></div><a href=/publication/toshev-2024-neuralsph/ class=summary-link><div class=article-style>Smoothed particle hydrodynamics (SPH) is omnipresent in modern engineering and scientific disciplines. SPH is a class of Lagrangian …</div></a><div class="stream-meta article-metadata"><div><span>Artur P. Toshev</span>, <span>Jonas A. Erbesdobler</span>, <span>Nikolaus A. Adams</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://iclr.cc/media/iclr-2024/Slides/21337.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/toshev-2024-neuralsph/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/tumaer/neuralsph target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arturtoshev.github.io/neural-sph-blog target=_blank rel=noopener>Project
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/media/CGAN-ICML-2023.pdf target=_blank rel=noopener>Poster</a></div></div><div class=ml-3><a href=/publication/toshev-2024-neuralsph/><img src=/publication/toshev-2024-neuralsph/featured_hu08a1320c51df6fc9e36a259a35fa511e_1441820_9bb0fcdb8e325a0619bf7fc614d7037e.png data-src=/publication/toshev-2024-neuralsph/featured_hu08a1320c51df6fc9e36a259a35fa511e_1441820_150x0_resize_lanczos_3.png alt="We identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of GNN-based simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components." class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/akhound-sadegh-2023-lps-pinn/>Lie Point Symmetries and Physics-Informed Networks</a></div><a href=/publication/akhound-sadegh-2023-lps-pinn/ class=summary-link><div class=article-style>We present how to use Lie Point Symmetries of PDEs to improve physics-informed neural networks. Published at NeurIPS 2023.</div></a><div class="stream-meta article-metadata"><div><span>Tara Akhound-Sadegh</span>, <span>Laurence Perreault-Levasseur</span>, <span>Johannes Brandstetter</span>, <span>Max Welling</span>, <span>Siamak Ravanbakhsh</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2311.04293 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/akhound-sadegh-2023-lps-pinn/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/akhound-sadegh-2023-lps-pinn/><img src=/publication/akhound-sadegh-2023-lps-pinn/featured_hu863a51d328e2cd7c6a4d35a71fb85dad_27767_076d7aeca8b40f912b2092a78339a1b9.png data-src=/publication/akhound-sadegh-2023-lps-pinn/featured_hu863a51d328e2cd7c6a4d35a71fb85dad_27767_150x0_resize_lanczos_3.png alt="Lie Point Symmetries and Physics-Informed Networks" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/lippe-2023-pderefiner/>PDE-Refiner - Achieving Accurate Long Rollouts with Neural PDE Solvers</a></div><a href=/publication/lippe-2023-pderefiner/ class=summary-link><div class=article-style>PDE-Refiner is an iterative refinement process that enables neural operator training for accurate and stable predictions over long time horizons. Published at NeurIPS 2023 (Spotlight).</div></a><div class="stream-meta article-metadata"><div><span>Phillip Lippe</span>, <span>Bastiaan S. Veeling</span>, <span>Paris Perdikaris</span>, <span>Richard E. Turner</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2308.05732 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/lippe-2023-pderefiner/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://microsoft.github.io/pdearena/ target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://phlippe.github.io/PDERefiner/ target=_blank rel=noopener>Project
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://phlippe.github.io/media/PDERefiner_F4LCD_Poster.pdf target=_blank rel=noopener>Poster
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://phlippe.github.io/media/PDERefiner_Slides.pdf target=_blank rel=noopener>Slides
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/N4IGE6pH7v8 target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/publication/lippe-2023-pderefiner/><img src=/publication/lippe-2023-pderefiner/featured_huee38579d1f3860c5b9f6758290dc258a_68766_7befbe80ef5c622749b8b601e12673b7.png data-src=/publication/lippe-2023-pderefiner/featured_huee38579d1f3860c5b9f6758290dc258a_68766_150x0_resize_lanczos_3.png alt="PDE-Refiner - Achieving Accurate Long Rollouts with Neural PDE Solvers" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/toshev-2023-lagrangian/>Learning Lagrangian Fluid Mechanics with E(3)-Equivariant Graph Neural Networks</a></div><a href=/publication/toshev-2023-lagrangian/ class=summary-link><div class=article-style>We introduce E(3)-equivariant GNNs to two well-studied fluid-flow systems, namely 3D decaying Taylor-Green vortex and 3D reverse Poiseuille flow. Published at GSI 2023.</div></a><div class="stream-meta article-metadata"><div><span>Artur P. Toshev</span>, <span>Gianluca Galletti</span>, <span>Johannes Brandstetter</span>, <span>Stefan Adami</span>, <span>Nikolaus A. Adams</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2305.15603 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/toshev-2023-lagrangian/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/tumaer/sph-hae target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/toshev-2023-lagrangian/><img src=/publication/toshev-2023-lagrangian/featured_hua447d8dbd932acd8d3c0cdf887945c3d_2887471_151782d1a7d4bcb3abad4e4d66028bbd.png data-src=/publication/toshev-2023-lagrangian/featured_hua447d8dbd932acd8d3c0cdf887945c3d_2887471_150x0_resize_lanczos_3.png alt="Learning Lagrangian Fluid Mechanics with E(3)-Equivariant Graph Neural Networks" class=lazyload></a></div></div><div class=see-all><a href=/publication/>See all publications
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=contact class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Open Positions</h1></div><div class="col-12 col-lg-8"><style type=text/css rel=stylesheet>li:not(:last-child){margin-bottom:7px}</style><div style=overflow-y:scroll;max-height:400px><p><strong>[Nov 2023]</strong> Open positions can be found <a href=https://www.jku.at/en/lit-artificial-intelligence-lab/graduate-school/open-positions/#c172980 target=_blank rel=noopener>here</a>.</p></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by>Published with
<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> —
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script>const code_highlighting=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",event:"Events",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script>window.netlifyIdentity&&window.netlifyIdentity.on("init",e=>{e||window.netlifyIdentity.on("login",()=>{document.location.href="/admin/"})})</script><script src=/js/wowchemy.min.2715644373c13ab983bf49e4043ffe04.js></script></body></html>