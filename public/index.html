<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.0.0-beta.1 for Hugo"><meta name=author content="Johannes Brandstetter"><meta name=description content="Co-founder and Chief Scientist @ Emmi AI, Assistant Professor @ JKU Linz"><link rel=alternate hreflang=en-us href=https://brandstetter-johannes.github.io/><link rel=preconnect href=https://fonts.gstatic.com crossorigin><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin=anonymous async></script><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.b17ce4f35976ea0b0e8e0291231cd424.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script><link rel=alternate href=/index.xml type=application/rss+xml title="Johannes Brandstetter"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://brandstetter-johannes.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Johannes Brandstetter"><meta property="og:url" content="https://brandstetter-johannes.github.io/"><meta property="og:title" content="Johannes Brandstetter"><meta property="og:description" content="Co-founder and Chief Scientist @ Emmi AI, Assistant Professor @ JKU Linz"><meta property="og:image" content="https://brandstetter-johannes.github.io/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://brandstetter-johannes.github.io/images/icon_hu3751bf80caad288f7f32134a8ecae786_4078_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2024-06-06T12:55:17+02:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://brandstetter-johannes.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://brandstetter-johannes.github.io/"}</script><title>Johannes Brandstetter</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.cbbd96bcb05c8aeb233b6e67999f793a.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Johannes Brandstetter</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Johannes Brandstetter</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#nxai data-target=#nxai><span>Emmi AI</span></a></li><li class=nav-item><a class=nav-link href=/#news data-target=#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#research data-target=#research><span>Research</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/experience/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/experience/#teaching><span>Teaching</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Open Positions</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" src=/authors/admin/avatar_hu1f007011a52cba17d97fb088d354cb34_1513563_270x270_fill_q98_lanczos_center.jpg alt="Johannes Brandstetter"><div class=portrait-title><h2>Johannes Brandstetter</h2><h3>Co-founder and Chief Scientist @ Emmi AI, Assistant Professor @ JKU Linz</h3><h3><a href=https://www.jku.at/en/institute-for-machine-learning/ target=_blank rel=noopener><span>Johannes Kepler University, Linz, Institute for Machine Learning</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=https://github.com/brandstetter-johannes target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://twitter.com/jo_brandstetter target=_blank rel=noopener aria-label=twitter><i class="fab fa-twitter big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=KiRvOHcAAAAJ&amp;hl=en" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/johannes-brandstetter-55741b116/ target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li><li><a href=mailto:brandstetter@ml.jku.at aria-label=envelope><i class="far fa-envelope big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>About me</h1><div class=article-style><p>I am leading a group &ldquo;AI for data-driven simulations&rdquo; at the <a href=https://www.jku.at/en/institute-for-machine-learning/ target=_blank rel=noopener>Institute for Machine Learning</a> at the Johannes Kepler University (JKU) Linz. Additionally, I am a Co-founder and Chief Scientist at <a href=https://www.emmi.ai/ target=_blank rel=noopener>Emmi AI</a> - our push towards the data-driven revolution in science/engineering.</p><p>I have obtained my PhD after working several years at the <a href=https://cms.cern/ target=_blank rel=noopener>CMS experiment at CERN</a>. During this time, I had the privilege of learning from brilliant minds from all around the world, and got the chance to co-author seminal papers in the realm of Higgs boson physics. In 2018, after completing my PhD, my career trajectory shifted towards machine learning, and I was fortunate to join the research group of Mr LSTM Sepp Hochreiter in Linz. Under Sepp&rsquo;s mentorship, I delved into the intricacies of machine learning and modern deep learning over a span of 2.5 years.</p><p>From 2021 to 2023, I had the pleasure of spending three remarkable years in Amsterdam.
Initially, I was part of the <a href=https://amlab.science.uva.nl/ target=_blank rel=noopener>Amsterdam Machine Learning Lab</a> lead by Max Welling, and subsequently joined Microsoft Research for 2 years. During this period, my passion for Geometric Deep Learning, particularly involving <a href=https://microsoft.github.io/cliffordlayers/ target=_blank rel=noopener>Geometric (Clifford) algebras</a>, and my interest in partial differential equations (PDEs), with a particular focus on <a href=https://microsoft.github.io/pdearena/ target=_blank rel=noopener>developing neural surrogates for (PDEs)</a>, became profound. Most importantly, I pivoted towards large-scale PDEs, <a href=https://microsoft.github.io/ClimaX/ target=_blank rel=noopener>including weather and climate modeling</a>, which culminated in <a href=https://arxiv.org/abs/2405.13063 target=_blank rel=noopener>Aurora</a>.</p><p>My years in Amsterdam have shaped <a href=https://brandstetter-johannes.github.io/research/data-driven-simulations/ target=_blank rel=noopener>my research vision</a>. I am firmly convinced that AI is on the cusp of disrupting simulations at industry-scale. Every day thousands and thousands of compute hours are spent on turbulence modeling, simulations of fluid or air flows, heat transfer in materials, traffic flows, and many more. Many of these processes follow similar underlying patterns, but yet need different and extremely specialized softward to simulate. Even worse, for different parameter settings the costly simulations need to be run at full length from scratch.</p><p>This is what I want to change! Therefore, I have started a new group at JKU Linz which has strong computer vision, numerical simulation, and engineering components. We want to advance data-driven simulations at industry-scale, and place the Austrian industry engine Linz as a center for doing that.</p></div><div class=row></div></div></div></div></section><section id=nxai class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Emmi AI</h1></div><div class="col-12 col-lg-8"><style type=text/css rel=stylesheet>li:not(:last-child){margin-bottom:7px}</style><div style=overflow-y:scroll;max-height:400px><p><strong>About Emmi AI</strong></p><p>At Emmi AI, we believe that the next frontier of industrial engineering lies at the intersection of artificial intelligence and physics. The world of large-scale engineering and manufacturing is ripe for transformation, yet today&rsquo;s innovation processes are hindered by slow, costly simulations and prohibitive computational requirements.</p><p>Emmi AI is here to change that.</p><p>Our vision is bold: to pioneer universally applicable AI-driven physics simulation models that accelerate engineering and manufacturing processes across industries – from aviation and energy to semiconductors, automotive and chemicals. We aim to enable real-time interaction, streamline production planning, and unlock new possibilities in design optimization.</p><p>The future we envision is one where AI surrogates reduce computational costs, foster rapid innovation, and drive industrial-scale engineering at unprecedented speeds. Our starting point is computational fluid dynamics (CFD), but our ambition extends to real-time adaptive simulations and multi-physics models.</p><p>Industrial-scale problems demand industrial-scale solutions. Much like medium-range weather forecasting challenged deep learning due to its scale, industrial simulations with tens of millions of mesh cells present a similar challenge – one we are ready to tackle. We are inspired by the ambition and intellectual rigor of Emmy Noether, whose groundbreaking contributions to physics mirror our commitment to redefining industrial engineering.</p><p>Emmi AI is not just building models; we are building the future of industrial innovation. As we scale, we seek partners who share our conviction: that AI is not merely a tool, but a catalyst for transforming how we design, build, and innovate.</p><p>To our investors, collaborators, and future team members – join us as we push the boundaries of what’s possible. Together, we will unlock a new era of efficiency, creativity, and excellence in engineering.</p><p>Let&rsquo;s build the future!</p><p>More information can be found at our webpage <a href=https://www.emmi.ai/ target=_blank rel=noopener>https://www.emmi.ai/</a>.</p></div></div></div></div></section><section id=news class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>News</h1></div><div class="col-12 col-lg-8"><style type=text/css rel=stylesheet>li:not(:last-child){margin-bottom:7px}</style><div style=overflow-y:scroll;max-height:400px><p><strong>[Feb 2025]</strong> Together with Dennis Just and Miks Mikelsons I have co-founded <a href=https://www.emmi.ai/ target=_blank rel=noopener>Emmi AI</a>.</p><p><strong>[Feb 2024]</strong> I have started as Chief Researcher at <a href=https://www.nx-ai.com/ target=_blank rel=noopener>NXAI</a>.</p><p><strong>[Oct 2023]</strong> I have re-joined Sepp Hochreiter&rsquo;s group, starting my own group “AI for data-driven simulations”</p></div></div></div></div></section><section id=research class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Research</h1></div><div class="col-12 col-lg-8"><div class=card-simple><div class=article-metadata><span class=article-date>Oct 1, 2023</span></div><a href=/research/data-driven-simulations/><div class=img-hover-zoom><img src=/research/data-driven-simulations/featured_hue401cb86d10535f004ebf0cc43f5e634_94256_77c7abc521347cc0595e7fca117ee9ef.jpg data-src=/research/data-driven-simulations/featured_hue401cb86d10535f004ebf0cc43f5e634_94256_808x455_fill_q98_lanczos_smart1.jpg class="article-banner lazyload" alt="Data-Driven Simulations"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/data-driven-simulations/>Data-Driven Simulations</a></div><a href=/research/data-driven-simulations/ class=summary-link><div class=article-style><p>I am firmly convinced that AI is on the cusp of disrupting simulations at industry-scale. Therefore, I have started a new group at JKU Linz which has strong computer vision, simulation, and engineering components. My vision is shaped by experience both from university and from industry.</p></div></a></div><div class=card-simple><div class=article-metadata><span class=article-date>Jan 1, 2021</span></div><a href=/research/geometric-deep-learning/><div class=img-hover-zoom><img src=/research/geometric-deep-learning/featured_hu7b08722431809de100db678e0bffd13c_206534_d4b701889b35ba8dd17722c20929a93e.png data-src=/research/geometric-deep-learning/featured_hu7b08722431809de100db678e0bffd13c_206534_808x455_fill_lanczos_smart1_3.png class="article-banner lazyload" alt="Geometric Deep Learning"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/geometric-deep-learning/>Geometric Deep Learning</a></div><a href=/research/geometric-deep-learning/ class=summary-link><div class=article-style><p>My passion for Geometric Deep Learning can be unmistakenly traced back to my physics background. I have contributed to the fields of graph neural networks, equivariant architectures, and neural PDE solvers. Furthermore, I have lead efforts to introduce Lie Point Symmetries, and, most recently, Clifford (Geometric) Algebras into the Deep Learning community.</p></div></a></div><div class=card-simple><div class=article-metadata><span class=article-date>Jul 1, 2018</span></div><a href=/research/deep-learning/><div class=img-hover-zoom><img src=/research/deep-learning/featured_huf25e885b1382cb4857aade30badbe625_95866_8dad8ff826763cc5cef3566170f17fd2.jpg data-src=/research/deep-learning/featured_huf25e885b1382cb4857aade30badbe625_95866_808x455_fill_q98_lanczos_smart1.jpg class="article-banner lazyload" alt="General Deep Learning"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/deep-learning/>General Deep Learning</a></div><a href=/research/deep-learning/ class=summary-link><div class=article-style><p>After switching from High Energy Physics to Deep Learning, I started working in Reinforcement Learning before pivoting towards Associative Memories and modern Transformer networks. Recent years have shown that scalable ideas, improving the datasets, and clever engineering are the ingredients for ever better Deep Learning models. This totally coincides with my experience, and &ndash; needless to say &ndash; I will continue working on general large-scale Deep Learning directions.</p></div></a></div><div class=card-simple><div class=article-metadata><span class=article-date>Jan 1, 2014</span></div><a href=/research/high-energy-physics/><div class=img-hover-zoom><img src=/research/high-energy-physics/featured_hud771b9de0130cb391febb22251a3c944_589960_7f657de0bb61435ccdd77358dfae50f1.jpg data-src=/research/high-energy-physics/featured_hud771b9de0130cb391febb22251a3c944_589960_808x455_fill_q98_lanczos_smart1.jpg class="article-banner lazyload" alt="High Energy Physics"></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/research/high-energy-physics/>High Energy Physics</a></div><a href=/research/high-energy-physics/ class=summary-link><div class=article-style><p>I have spent five years (including my PhD) working in the CMS Collaboration at CERN. Most of my research was dedicated to Higgs boson physics.</p></div></a></div></div></div></div></section><section id=publications class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Recent (selected) Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/alkin-2024-vision-lstm/>Vision-LSTM -- xLSTM as Generic Vision Backbone</a></div><a href=/publication/alkin-2024-vision-lstm/ class=summary-link><div class=article-style>We introduce Vision-LSTM (ViL), an adaption of the xLSTM building blocks to computer vision.</div></a><div class="stream-meta article-metadata"><div><span>Benedikt Alkin</span>, <span>Maximilian Beck</span>, <span>Korbinian Poeppel</span>, <span>Sepp Hochreiter</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2406.04303 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/alkin-2024-vision-lstm/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/nx-ai/vision-lstm target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://nx-ai.github.io/vision-lstm/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/alkin-2024-vision-lstm/><img src=/publication/alkin-2024-vision-lstm/featured_hudc4623eacaae69c19ae834e37cff285c_36506_e437b74b6f5d8a5f1fb330f4e22ff240.png data-src=/publication/alkin-2024-vision-lstm/featured_hudc4623eacaae69c19ae834e37cff285c_36506_150x0_resize_lanczos_3.png alt="Vision-LSTM -- xLSTM as Generic Vision Backbone" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/bodnar-2024-aurora/>Aurora -- A foundation Model of the Atmosphere</a></div><a href=/publication/bodnar-2024-aurora/ class=summary-link><div class=article-style>Aurora leverages the strengths of the foundation modelling approach to produce operational forecasts for a wide variety of atmospheric prediction problems, including those with limited training data, heterogeneous variables, and extreme events</div></a><div class="stream-meta article-metadata"><div><span>Cristian Bodnar</span>, <span>Wessel W. Bruinsma</span>, <span>Ana Lucic</span>, <span>Megan Stanley</span>, <span>Johannes Brandstetter</span>, <span>Patrick Garvan</span>, <span>Maik Riechert</span>, <span>Jonathan Weyn</span>, <span>Haiyu Dong</span>, <span>Anna Vaughan</span>, <span>Jayesh K. Gupta</span>, <span>Kit Tambiratnam</span>, <span>Alex Archibald</span>, <span>Elizabeth Heider</span>, <span>Max Welling</span>, <span>Rich E. Turner</span>, <span>Paris Perdikaris</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.13063 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/bodnar-2024-aurora/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/bodnar-2024-aurora/><img src=/publication/bodnar-2024-aurora/featured_hu2e05b0091c591a24c8fe12ec320bac9f_493434_021713b50ff83196d70af531b1cab84b.png data-src=/publication/bodnar-2024-aurora/featured_hu2e05b0091c591a24c8fe12ec320bac9f_493434_150x0_resize_lanczos_3.png alt="Aurora -- A foundation Model of the Atmosphere" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/beck-2024-xlstm/>xLSTM -- Extended Long Short-Term Memory</a></div><a href=/publication/beck-2024-xlstm/ class=summary-link><div class=article-style>How far do we get in language modeling when scaling LSTMs to billions of parameters, leveraging the latest techniques from modern LLMs, but mitigating known limitations of LSTMs?</div></a><div class="stream-meta article-metadata"><div><span>Maximilian Beck</span>, <span>Korbinian Poeppel</span>, <span>Markus Spanring</span>, <span>Andreas Auer</span>, <span>Oleksandra Prudnikova</span>, <span>Michael Kopp</span>, <span>Günter Klambauer</span>, <span>Johannes Brandstetter</span>, <span>Sepp Hochreiter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2405.04517 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/beck-2024-xlstm/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/NX-AI/xlstm target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/beck-2024-xlstm/><img src=/publication/beck-2024-xlstm/featured_hu96a6b6c3934663291bddbc1f38c55003_45653_6cbb14190b190118df507f15f771a4b0.png data-src=/publication/beck-2024-xlstm/featured_hu96a6b6c3934663291bddbc1f38c55003_45653_150x0_resize_lanczos_3.png alt="xLSTM -- Extended Long Short-Term Memory" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/berzins-2024-ginns/>Geometry-Informed Neural Networks</a></div><a href=/publication/berzins-2024-ginns/ class=summary-link><div class=article-style>We introduce geometry-informed neural networks (GINNs) to train shape generative models without any data.</div></a><div class="stream-meta article-metadata"><div><span>Arturs Berzins</span>, <span>Andreas Radler</span>, <span>Sebastian Sanokowski</span>, <span>Sepp Hochreiter</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.14009 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/berzins-2024-ginns/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ml-jku/GINNs-Geometry-informed-Neural-Networks target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arturs-berzins.github.io/GINN/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/berzins-2024-ginns/><img src=/publication/berzins-2024-ginns/featured_hu37d8aae38d48dfc801ecb4736e7af687_692903_eabd3f947e9b8ea73fd66b3777c59c49.png data-src=/publication/berzins-2024-ginns/featured_hu37d8aae38d48dfc801ecb4736e7af687_692903_150x0_resize_lanczos_3.png alt="Geometry-Informed Neural Networks" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/alkin-2024-upt/>Universal Physics Transformers -- A Framework For Efficiently Scaling Neural Operators</a></div><a href=/publication/alkin-2024-upt/ class=summary-link><div class=article-style>We introduce Universal Physics Transformers (UPTs), an efficient and unified learning paradigm for a wide range of spatio-temporal problems. UPTs operate without grid- or particle-based latent structures, enabling flexibility and scalability across meshes and particles.</div></a><div class="stream-meta article-metadata"><div><span>Benedikt Alkin</span>, <span>Andreas Fürst</span>, <span>Simon Schmid</span>, <span>Lukas Gruber</span>, <span>Markus Holzleitner</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.12365 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/alkin-2024-upt/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ml-jku/UPT target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ml-jku.github.io/UPT/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/alkin-2024-upt/><img src=/publication/alkin-2024-upt/featured_hu8b80630a582cbf42c3458ce96d5a4590_157838_1789609c5e2488d2efbb1e27275ceddb.png data-src=/publication/alkin-2024-upt/featured_hu8b80630a582cbf42c3458ce96d5a4590_157838_150x0_resize_lanczos_3.png alt="Universal Physics Transformers -- A Framework For Efficiently Scaling Neural Operators" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/alkin-2024-mimrefiner/>Mim-refiner -- A contrastive learning boost from intermediate pre-trained representations</a></div><a href=/publication/alkin-2024-mimrefiner/ class=summary-link><div class=article-style>We introduce MIM (Masked Image Modeling)-Refiner, a contrastive learning boost for pre-trained MIM models.</div></a><div class="stream-meta article-metadata"><div><span>Benedikt Alkin</span>, <span>Lukas Miklautz</span>, <span>Sepp Hochreiter</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2402.10093 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/alkin-2024-mimrefiner/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ml-jku/MIM-Refiner target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://ml-jku.github.io/MIM-Refiner/ target=_blank rel=noopener>Project</a></div></div><div class=ml-3><a href=/publication/alkin-2024-mimrefiner/><img src=/publication/alkin-2024-mimrefiner/featured_hu5a9807048c46ae96d8b399109037ff64_47175_9363d30b4d206a43165d9a31b6d92bd9.png data-src=/publication/alkin-2024-mimrefiner/featured_hu5a9807048c46ae96d8b399109037ff64_47175_150x0_resize_lanczos_3.png alt="Mim-refiner -- A contrastive learning boost from intermediate pre-trained representations" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/toshev-2024-neuralsph/>NeuralSPH -- Improved neural modeling of lagrangian fluid dynamics</a></div><a href=/publication/toshev-2024-neuralsph/ class=summary-link><div class=article-style>We identify particle clustering originating from tensile instabilities as one of the primary pitfalls. Based on these insights, we enhance both training and rollout inference of GNN-based simulators with varying components from standard SPH solvers, including pressure, viscous, and external force components.</div></a><div class="stream-meta article-metadata"><div><span>Artur P. Toshev</span>, <span>Jonas A. Erbesdobler</span>, <span>Nikolaus A. Adams</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://iclr.cc/media/iclr-2024/Slides/21337.pdf target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/toshev-2024-neuralsph/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/tumaer/neuralsph target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arturtoshev.github.io/neural-sph-blog target=_blank rel=noopener>Project
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=/media/CGAN-ICML-2023.pdf target=_blank rel=noopener>Poster</a></div></div><div class=ml-3><a href=/publication/toshev-2024-neuralsph/><img src=/publication/toshev-2024-neuralsph/featured_hu08a1320c51df6fc9e36a259a35fa511e_1441820_9bb0fcdb8e325a0619bf7fc614d7037e.png data-src=/publication/toshev-2024-neuralsph/featured_hu08a1320c51df6fc9e36a259a35fa511e_1441820_150x0_resize_lanczos_3.png alt="NeuralSPH -- Improved neural modeling of lagrangian fluid dynamics" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/akhound-sadegh-2023-lps-pinn/>Lie Point Symmetries and Physics-Informed Networks</a></div><a href=/publication/akhound-sadegh-2023-lps-pinn/ class=summary-link><div class=article-style>We present how to use Lie Point Symmetries of PDEs to improve physics-informed neural networks. Published at NeurIPS 2023.</div></a><div class="stream-meta article-metadata"><div><span>Tara Akhound-Sadegh</span>, <span>Laurence Perreault-Levasseur</span>, <span>Johannes Brandstetter</span>, <span>Max Welling</span>, <span>Siamak Ravanbakhsh</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2311.04293 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/akhound-sadegh-2023-lps-pinn/cite.bib>Cite</a></div></div><div class=ml-3><a href=/publication/akhound-sadegh-2023-lps-pinn/><img src=/publication/akhound-sadegh-2023-lps-pinn/featured_hu863a51d328e2cd7c6a4d35a71fb85dad_27767_076d7aeca8b40f912b2092a78339a1b9.png data-src=/publication/akhound-sadegh-2023-lps-pinn/featured_hu863a51d328e2cd7c6a4d35a71fb85dad_27767_150x0_resize_lanczos_3.png alt="Lie Point Symmetries and Physics-Informed Networks" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/lippe-2023-pderefiner/>PDE-Refiner - Achieving Accurate Long Rollouts with Neural PDE Solvers</a></div><a href=/publication/lippe-2023-pderefiner/ class=summary-link><div class=article-style>PDE-Refiner is an iterative refinement process that enables neural operator training for accurate and stable predictions over long time horizons. Published at NeurIPS 2023 (Spotlight).</div></a><div class="stream-meta article-metadata"><div><span>Phillip Lippe</span>, <span>Bastiaan S. Veeling</span>, <span>Paris Perdikaris</span>, <span>Richard E. Turner</span>, <span>Johannes Brandstetter</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2308.05732 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/lippe-2023-pderefiner/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://microsoft.github.io/pdearena/ target=_blank rel=noopener>Code
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://phlippe.github.io/PDERefiner/ target=_blank rel=noopener>Project
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://phlippe.github.io/media/PDERefiner_F4LCD_Poster.pdf target=_blank rel=noopener>Poster
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://phlippe.github.io/media/PDERefiner_Slides.pdf target=_blank rel=noopener>Slides
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://youtu.be/N4IGE6pH7v8 target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/publication/lippe-2023-pderefiner/><img src=/publication/lippe-2023-pderefiner/featured_huee38579d1f3860c5b9f6758290dc258a_68766_7befbe80ef5c622749b8b601e12673b7.png data-src=/publication/lippe-2023-pderefiner/featured_huee38579d1f3860c5b9f6758290dc258a_68766_150x0_resize_lanczos_3.png alt="PDE-Refiner - Achieving Accurate Long Rollouts with Neural PDE Solvers" class=lazyload></a></div></div><div class="media stream-item"><div class=media-body><div class="section-subheading article-title mb-0 mt-0"><a href=/publication/toshev-2023-lagrangian/>Learning Lagrangian Fluid Mechanics with E(3)-Equivariant Graph Neural Networks</a></div><a href=/publication/toshev-2023-lagrangian/ class=summary-link><div class=article-style>We introduce E(3)-equivariant GNNs to two well-studied fluid-flow systems, namely 3D decaying Taylor-Green vortex and 3D reverse Poiseuille flow. Published at GSI 2023.</div></a><div class="stream-meta article-metadata"><div><span>Artur P. Toshev</span>, <span>Gianluca Galletti</span>, <span>Johannes Brandstetter</span>, <span>Stefan Adami</span>, <span>Nikolaus A. Adams</span></div></div><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2305.15603 target=_blank rel=noopener>PDF
</a><a href=# class="btn btn-outline-primary btn-page-header btn-sm js-cite-modal" data-filename=/publication/toshev-2023-lagrangian/cite.bib>Cite
</a><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/tumaer/sph-hae target=_blank rel=noopener>Code</a></div></div><div class=ml-3><a href=/publication/toshev-2023-lagrangian/><img src=/publication/toshev-2023-lagrangian/featured_hua447d8dbd932acd8d3c0cdf887945c3d_2887471_151782d1a7d4bcb3abad4e4d66028bbd.png data-src=/publication/toshev-2023-lagrangian/featured_hua447d8dbd932acd8d3c0cdf887945c3d_2887471_150x0_resize_lanczos_3.png alt="Learning Lagrangian Fluid Mechanics with E(3)-Equivariant Graph Neural Networks" class=lazyload></a></div></div><div class=see-all><a href=/publication/>See all publications
<i class="fas fa-angle-right"></i></a></div></div></div></div></section><section id=contact class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Open Positions</h1></div><div class="col-12 col-lg-8"><style type=text/css rel=stylesheet>li:not(:last-child){margin-bottom:7px}</style><div style=overflow-y:scroll;max-height:400px><p><strong>[Nov 2023]</strong> Open positions can be found <a href=https://www.jku.at/en/lit-artificial-intelligence-lab/graduate-school/open-positions/#c172980 target=_blank rel=noopener>here</a>.</p></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class=powered-by></p><p class=powered-by>Published with
<a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> —
the free, <a href=https://github.com/wowchemy/wowchemy-hugo-modules target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/r.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin=anonymous></script><script>const code_highlighting=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",event:"Events",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script><script>window.netlifyIdentity&&window.netlifyIdentity.on("init",e=>{e||window.netlifyIdentity.on("login",()=>{document.location.href="/admin/"})})</script><script src=/js/wowchemy.min.2715644373c13ab983bf49e4043ffe04.js></script></body></html>